{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c66ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import fitz\n",
    "from io import BytesIO\n",
    "import getpass\n",
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.llms import HuggingFaceEndpoint\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11bdf04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6f6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from url\n",
    "def extract_text_from_pdf_url(pdf_url):\n",
    "    response = requests.get(pdf_url)\n",
    "    with fitz.open(\"pdf\", BytesIO(response.content)) as doc:\n",
    "        return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "# Connecting with Pinecone\n",
    "def connect_to_pinecone():\n",
    "    if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "        os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "    pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "    index_name = \"rpapers\" \n",
    "\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "    print(existing_indexes)\n",
    "\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=os.environ[\"PINECONE_ENV\"]),\n",
    "        )\n",
    "        while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "            time.sleep(1)\n",
    "\n",
    "    index = pc.Index(index_name)\n",
    "    return index\n",
    "\n",
    "# Set up embeddings\n",
    "def set_embddings(url):\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    text = extract_text_from_pdf_url(url)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=240)\n",
    "    chunks = splitter.create_documents([text])\n",
    "    return embeddings, chunks\n",
    "\n",
    "# add element to vector store\n",
    "def vector_store_and_chunking(index, embeddings, chunks):\n",
    "    vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "    documents = [Document(page_content=chunk.page_content, metadata={\"source\": \"arxiv_2301.00001\"}) for chunk in chunks]\n",
    "    uuids = [str(uuid4()) for _ in documents]\n",
    "    vector_store.add_documents(documents=documents, ids=uuids)\n",
    "    return vector_store\n",
    "\n",
    "def query_llm(vector_store, question, llm):\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", k=4)\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    response = qa(question)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be29e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://arxiv.org/pdf/1608.04434v1', 'http://arxiv.org/pdf/2503.02435v1', 'http://arxiv.org/pdf/2202.07138v2']\n",
      "['rpapers']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "d:\\Python\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.3 (Request ID: Root=1-680947ec-2c4ff9922ea1ecec1ecc5715;8d1384f5-f889-4dc1-a406-6fe0147e1411)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 35\u001b[0m\n\u001b[0;32m     26\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceEndpoint(\n\u001b[0;32m     27\u001b[0m     repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the paper about?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🧠 Answer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔍 Source Chunks:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 59\u001b[0m, in \u001b[0;36mquery_llm\u001b[1;34m(vector_store, question, llm)\u001b[0m\n\u001b[0;32m     51\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     53\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m     54\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     55\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[0;32m     56\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     57\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mqa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mwarning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarning_emitting_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for the original wrapped callable that emits a warning.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;124;03m        *args: The positional arguments to the function.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m        **kwargs: The keyword arguments to the function.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        The return value of the function being wrapped.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m warned\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:154\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mwarning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarning_emitting_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for the original wrapped callable that emits a warning.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;124;03m        *args: The positional arguments to the function.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m        **kwargs: The keyword arguments to the function.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        The return value of the function being wrapped.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m warned\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mwarning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarning_emitting_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for the original wrapped callable that emits a warning.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;124;03m        *args: The positional arguments to the function.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m        **kwargs: The keyword arguments to the function.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        The return value of the function being wrapped.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m warned\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:259\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\llm.py:318\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mwarning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarning_emitting_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for the original wrapped callable that emits a warning.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;124;03m        *args: The positional arguments to the function.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m        **kwargs: The keyword arguments to the function.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        The return value of the function being wrapped.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m warned\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:760\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    758\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m    759\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m--> 760\u001b[0m     callbacks: Optional[Union[Callbacks, \u001b[38;5;28mlist\u001b[39m[Callbacks]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    762\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    763\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:963\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m )\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m    960\u001b[0m             [prompt],\n\u001b[0;32m    961\u001b[0m             invocation_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    962\u001b[0m             options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m--> 963\u001b[0m             name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    964\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(prompts),\n\u001b[0;32m    965\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mrun_id_,\n\u001b[0;32m    966\u001b[0m         )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m callback_manager, prompt, run_name, run_id_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    968\u001b[0m             callback_managers, prompts, run_name_list, run_ids_list\n\u001b[0;32m    969\u001b[0m         )\n\u001b[0;32m    970\u001b[0m     ]\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    972\u001b[0m         prompts,\n\u001b[0;32m    973\u001b[0m         stop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:784\u001b[0m, in \u001b[0;36m_generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m     prompt_strings = [p.to_string() for p in prompts]\n\u001b[0;32m    775\u001b[0m     return await self.agenerate(\n\u001b[0;32m    776\u001b[0m         prompt_strings, stop=stop, callbacks=callbacks, **kwargs\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    779\u001b[0m def _generate_helper(\n\u001b[0;32m    780\u001b[0m     self,\n\u001b[0;32m    781\u001b[0m     prompts: list[str],\n\u001b[0;32m    782\u001b[0m     stop: Optional[list[str]],\n\u001b[0;32m    783\u001b[0m     run_managers: list[CallbackManagerForLLMRun],\n\u001b[1;32m--> 784\u001b[0m     *,\n\u001b[0;32m    785\u001b[0m     new_arg_supported: bool,\n\u001b[0;32m    786\u001b[0m     **kwargs: Any,\n\u001b[0;32m    787\u001b[0m ) -> LLMResult:\n\u001b[0;32m    788\u001b[0m     try:\n\u001b[0;32m    789\u001b[0m         output = (\n\u001b[0;32m    790\u001b[0m             self._generate(\n\u001b[0;32m    791\u001b[0m                 prompts,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    798\u001b[0m             else self._generate(prompts, stop=stop)\n\u001b[0;32m    799\u001b[0m         )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1523\u001b[0m, in \u001b[0;36m_generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acall\u001b[39m(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1500\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1504\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Async version of the _call method.\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \n\u001b[0;32m   1507\u001b[0m \u001b[38;5;124;03m    The default implementation delegates to the synchronous _call method using\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;124;03m        The model output as a string. SHOULD NOT include the prompt.\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call,\n\u001b[0;32m   1526\u001b[0m         prompt,\n\u001b[0;32m   1527\u001b[0m         stop,\n\u001b[0;32m   1528\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mget_sync() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1530\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\langchain_community\\llms\\huggingface_endpoint.py:267\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     invocation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m invocation_params[\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minvocation_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         response_text \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:132\u001b[0m, in \u001b[0;36m_deprecate_method.<locals>._inner_deprecate_method.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     warning_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message\n\u001b[0;32m    131\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(warning_message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:305\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    303\u001b[0m url \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39m_prepare_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken, mapped_model)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    304\u001b[0m headers \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39m_prepare_headers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRequestParameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munknown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munknown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:357\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[1;34m(self, request_parameters, stream)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-Instruct-v0.3 (Request ID: Root=1-680947ec-2c4ff9922ea1ecec1ecc5715;8d1384f5-f889-4dc1-a406-6fe0147e1411)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def search_arxiv(query, max_results=3):\n",
    "    query = quote(query)\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    search_url = f\"{base_url}search_query=all:{query}&start=0&max_results={max_results}\"\n",
    "    return feedparser.parse(search_url)\n",
    "\n",
    "results = search_arxiv(\"natural language processing\", max_results=3)\n",
    "\n",
    "all_urls = []\n",
    "for i, entry in enumerate(results.entries):\n",
    "    # print(f\"\\n📌 Title: {entry.title}\")\n",
    "    # print(f\"📝 Abstract: {entry.summary[:300]}...\\n\")\n",
    "    pdf_url = next(link.href for link in entry.links if link.type == \"application/pdf\")\n",
    "    all_urls.append(pdf_url)\n",
    "\n",
    "print(all_urls)\n",
    "index = connect_to_pinecone()\n",
    "embeddings, chunks = set_embddings(all_urls[0])\n",
    "vector_store = vector_store_and_chunking(index, embeddings, chunks)\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    temperature=0.6,\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.getenv(\"HF_TOKEN\"), \n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "question = \"What is the paper about?\"\n",
    "response = query_llm(vector_store, question, llm)\n",
    "\n",
    "print(\"🧠 Answer:\\n\", response[\"result\"])\n",
    "print(\"\\n🔍 Source Chunks:\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(\"-\", doc.page_content[:300].strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "231b4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_abstract(data):\n",
    "    if \".pdf\" in data:\n",
    "        doc = fitz.open(\"1706.03762v7.pdf\")\n",
    "\n",
    "        text = \"\"\n",
    "\n",
    "        for page in doc:\n",
    "            text+=page.get_text().lower()\n",
    "    else:\n",
    "        text=data\n",
    "    abstract_index = 0\n",
    "    try:\n",
    "        abstract_index = text.index(\"abstract\")\n",
    "        end_index = text.index(\"introduction\")\n",
    "    except Exception as e:\n",
    "        end_index = abstract_index+1000\n",
    "        print(e)\n",
    "    \n",
    "    return text[abstract_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8424eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://arxiv.org/pdf/2410.11977v4', 'http://arxiv.org/pdf/2502.08056v1', 'http://arxiv.org/pdf/2305.02878v1']\n",
      "substring not found\n",
      "The AI generation gap: Are Gen Z students more interested in adopting generative AI \n",
      "such as ChatGPT in teaching and learning than their Gen X and Millennial Generation \n",
      "teachers? \n",
      "Authors: Cecilia Ka Yuk Chan1* & Katherine K. W. Lee1 \n",
      " \n",
      "Affiliation1: The University of Hong Kong \n",
      "Address: Centre for the Enhancement of Teaching and Learning (CETL), Room CPD-1.81, \n",
      "Centennial Campus, The University of Hong Kong, Pokfulam, Hong Kong \n",
      " \n",
      "* Corresponding author. Email: cecilia.chan@cetl.hku.hk \n",
      "Email: kathkw@connect.hku.hk \n",
      " \n",
      "Abstract  \n",
      "This study aimed to explore the experiences, perceptions, knowledge, concerns, and \n",
      "intentions of Gen Z students with Gen X and Gen Y teachers regarding the use of generative \n",
      "AI (GenAI) in higher education. A sample of students and teachers were recruited to \n",
      "investigate the above using a survey consisting of both open and closed questions. The \n",
      "findings showed that Gen Z participants were generally optimistic about the potential benefits \n",
      "of GenAI, includin\n"
     ]
    }
   ],
   "source": [
    "results = search_arxiv(\"gen ai\", max_results=3)\n",
    "# print(results.entries)\n",
    "all_urls = []\n",
    "for i, entry in enumerate(results.entries):\n",
    "    pdf_url = next(link.href for link in entry.links if link.type == \"application/pdf\")\n",
    "    all_urls.append(pdf_url)\n",
    "\n",
    "print(all_urls)\n",
    "text = extract_text_from_pdf_url(all_urls[2])\n",
    "abstract = extract_abstract(text)\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b373b134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minimax', 'recognition', 'learning', 'min', 'samples']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "\n",
    "def extract_topics(text, top_n=5):\n",
    "    keywords = kw_model.extract_keywords(text, top_n=top_n, stop_words='english')\n",
    "    return [kw for kw, _ in keywords]\n",
    "\n",
    "extract_topics(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a994e",
   "metadata": {},
   "source": [
    "NEXT TASK - Extract DOI, search the paper for title and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc03bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 OCR Text Preview:\n",
      " 1706.03762v7 [cs.CL] 2 Aug 2023\n",
      "\n",
      "arXiv\n",
      "\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "\n",
      "Attention Is All You Need\n",
      "\n",
      "Ashish Vaswani* Noam Shazeer* Niki Parmar* Jakob Uszkoreit*\n",
      "Google Brain Google Brain Google Research Google Research\n",
      "avaswani@google.com noam@google.com nikip@google.com usz@google.com\n",
      "\n",
      "Llion Jones* Aidan N. Gomez* ¢ Lukasz Kaiser*\n",
      "Google Research University of Toronto Google Brain\n",
      "llion@google.com aidan@cs.toronto.edu lukaszkaiser@google.com\n",
      "\n",
      "Illia Polosukhin* +\n",
      "illia.polosukhin@gmail.com\n",
      "\n",
      "Abstract\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing \n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "images = convert_from_path(\"1706.03762v7.pdf\", first_page=1, last_page=1)\n",
    "image = images[0]\n",
    "\n",
    "text = pytesseract.image_to_string(image)\n",
    "print(\"🔍 OCR Text Preview:\\n\", text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c7527a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ arXiv ID: 1706.03762\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_arxiv_id(text):\n",
    "    match = re.search(r'(?:arXiv:)?(\\d{4}\\.\\d{4,5})(v\\d+)?', text)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "arxiv_id = extract_arxiv_id(text)\n",
    "print(\"✅ arXiv ID:\", arxiv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebb9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Title: Attention Is All You Need\n",
      "🧠 Abstract: The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, based\n",
      "solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to be\n",
      "superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014\n",
      "English-to-German translation task, improving over the existing best results,\n",
      "including ensembles by over 2 BLEU. On the WMT 2014 English-to-French\n",
      "translation task, our model establishes a new single-model state-of-the-art\n",
      "BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\n",
      "of the training costs of the best models from the literature. We show that the\n",
      "Transformer generalizes well to other tasks by applying it successfully to\n",
      "English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "def fetch_arxiv_metadata(arxiv_id):\n",
    "    url = f\"http://export.arxiv.org/api/query?id_list={arxiv_id}\"\n",
    "    feed = feedparser.parse(url)\n",
    "    if feed.entries:\n",
    "        entry = feed.entries[0]\n",
    "        return {\n",
    "            \"title\": entry.title.strip(),\n",
    "            \"abstract\": entry.summary.strip(),\n",
    "            \"authors\": [author.name for author in entry.authors],\n",
    "            \"published\": entry.published,\n",
    "            \"url\": entry.link\n",
    "        }\n",
    "    return None\n",
    "\n",
    "metadata = fetch_arxiv_metadata(arxiv_id)\n",
    "print(\"📄 Title:\", metadata[\"title\"])\n",
    "print(\"🧠 Abstract:\", metadata[\"abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31746822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['attention', 'decoder', 'encoder', 'parsing', 'neural']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "\n",
    "def extract_topics(text, top_n=5):\n",
    "    keywords = kw_model.extract_keywords(text, top_n=top_n, stop_words='english')\n",
    "    return [kw for kw, _ in keywords]\n",
    "\n",
    "extract_topics(metadata[\"title\"] + \" \" + metadata[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0b7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_tag_to_fullname = {\n",
    "    # 🧠 Computer Science\n",
    "    \"cs.AI\": \"Artificial Intelligence\",\n",
    "    \"cs.CL\": \"Computation and Language (NLP)\",\n",
    "    \"cs.CV\": \"Computer Vision and Pattern Recognition\",\n",
    "    \"cs.LG\": \"Machine Learning\",\n",
    "    \"cs.IR\": \"Information Retrieval\",\n",
    "    \"cs.SE\": \"Software Engineering\",\n",
    "    \"cs.DB\": \"Databases\",\n",
    "    \"cs.DS\": \"Data Structures and Algorithms\",\n",
    "    \"cs.RO\": \"Robotics\",\n",
    "    \"cs.CR\": \"Cryptography and Security\",\n",
    "    \"cs.SI\": \"Social and Information Networks\",\n",
    "\n",
    "    # 🔬 Other Scientific Domains\n",
    "    \"math.PR\": \"Probability\",\n",
    "    \"math.OC\": \"Optimization and Control\",\n",
    "    \"stat.ML\": \"Machine Learning (Statistics side)\",\n",
    "    \"physics.comp-ph\": \"Computational Physics\",\n",
    "    \"econ.EM\": \"Econometrics\",\n",
    "    \"q-fin.ML\": \"Quantitative Finance – ML\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5080a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence',\n",
       " 'Computation and Language (NLP)',\n",
       " 'Computer Vision and Pattern Recognition',\n",
       " 'Machine Learning',\n",
       " 'Information Retrieval',\n",
       " 'Software Engineering',\n",
       " 'Databases',\n",
       " 'Data Structures and Algorithms',\n",
       " 'Robotics',\n",
       " 'Cryptography and Security',\n",
       " 'Social and Information Networks',\n",
       " 'Probability',\n",
       " 'Optimization and Control',\n",
       " 'Machine Learning (Statistics side)',\n",
       " 'Computational Physics',\n",
       " 'Econometrics',\n",
       " 'Quantitative Finance – ML']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = list(arxiv_tag_to_fullname.values())\n",
    "topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97cbc3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_data(query, max_results, start_date, end_date):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    query = query.replace(\" \", \"+\")\n",
    "    search_url = f\"{base_url}search_query=all:{query}&start=0&max_results={max_results}&sortBy=relevance&sortOrder=descending\"\n",
    "    \n",
    "    feed = feedparser.parse(search_url)\n",
    "    papers = []\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        published_date = datetime.strptime(entry.published, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        if start_date and published_date < start_date:\n",
    "            continue\n",
    "        if end_date and published_date > end_date:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        papers.append({\n",
    "                \"title\": entry.title.strip(),\n",
    "                \"abstract\": entry.summary.strip(),\n",
    "                \"published\": published_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"tags\": entry.tags[0][\"term\"] if entry.tags else \"unknown\"\n",
    "            })\n",
    "    \n",
    "    return papers\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(2016, 1, 1)\n",
    "end = datetime(2020, 12, 31)\n",
    "\n",
    "data = []\n",
    "\n",
    "# for topic in topics:\n",
    "# print(topic)\n",
    "papers = fetch_data(\"Artificial Intelligence\", 200, start, end)\n",
    "len(papers)\n",
    "# print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e58ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'title': 'The Governance of Physical Artificial Intelligence',\n",
       "   'abstract': 'Physical artificial intelligence can prove to be one of the most important\\nchallenges of the artificial intelligence. The governance of physical\\nartificial intelligence would define its responsible intelligent application in\\nthe society.',\n",
       "   'published': '2023-04-06',\n",
       "   'tags': 'cs.AI'}],\n",
       " [{'title': 'NLP for The Greek Language: A Longer Survey',\n",
       "   'abstract': 'English language is in the spotlight of the Natural Language Processing (NLP)\\ncommunity with other languages, like Greek, lagging behind in terms of offered\\nmethods, tools and resources. Due to the increasing interest in NLP, in this\\npaper we try to condense research efforts for the automatic processing of Greek\\nlanguage covering the last three decades. In particular, we list and briefly\\ndiscuss related works, resources and tools, categorized according to various\\nprocessing layers and contexts. We are not restricted to the modern form of\\nGreek language but also cover Ancient Greek and various Greek dialects. This\\nsurvey can be useful for researchers and students interested in NLP tasks,\\nInformation Retrieval and Knowledge Management for the Greek language.',\n",
       "   'published': '2024-08-20',\n",
       "   'tags': 'cs.CL'}],\n",
       " [{'title': 'Second Croatian Computer Vision Workshop (CCVW 2013)',\n",
       "   'abstract': 'Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,\\nhttp://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,\\nCroatia. Workshop was organized by the Center of Excellence for Computer Vision\\nof the University of Zagreb.',\n",
       "   'published': '2013-10-01',\n",
       "   'tags': 'cs.CV'}],\n",
       " [{'title': 'Towards Modular Machine Learning Solution Development: Benefits and\\n  Trade-offs',\n",
       "   'abstract': \"Machine learning technologies have demonstrated immense capabilities in\\nvarious domains. They play a key role in the success of modern businesses.\\nHowever, adoption of machine learning technologies has a lot of untouched\\npotential. Cost of developing custom machine learning solutions that solve\\nunique business problems is a major inhibitor to far-reaching adoption of\\nmachine learning technologies. We recognize that the monolithic nature\\nprevalent in today's machine learning applications stands in the way of\\nefficient and cost effective customized machine learning solution development.\\nIn this work we explore the benefits of modular machine learning solutions and\\ndiscuss how modular machine learning solutions can overcome some of the major\\nsolution engineering limitations of monolithic machine learning solutions. We\\nanalyze the trade-offs between modular and monolithic machine learning\\nsolutions through three deep learning problems; one text based and the two\\nimage based. Our experimental results show that modular machine learning\\nsolutions have a promising potential to reap the solution engineering\\nadvantages of modularity while gaining performance and data advantages in a way\\nthe monolithic machine learning solutions do not permit.\",\n",
       "   'published': '2023-01-23',\n",
       "   'tags': 'cs.LG'}],\n",
       " [{'title': 'Explainable Information Retrieval: A Survey',\n",
       "   'abstract': 'Explainable information retrieval is an emerging research area aiming to make\\ntransparent and trustworthy information retrieval systems. Given the increasing\\nuse of complex machine learning models in search systems, explainability is\\nessential in building and auditing responsible information retrieval models.\\nThis survey fills a vital gap in the otherwise topically diverse literature of\\nexplainable information retrieval. It categorizes and discusses recent\\nexplainability methods developed for different application domains in\\ninformation retrieval, providing a common framework and unifying perspectives.\\nIn addition, it reflects on the common concern of evaluating explanations and\\nhighlights open challenges and opportunities.',\n",
       "   'published': '2022-11-04',\n",
       "   'tags': 'cs.IR'}],\n",
       " [{'title': 'The Study and Approach of Software Re-Engineering',\n",
       "   'abstract': \"The nature of software re-engineering is to improve or transform existing\\nsoftware so it can be understood, controlled and reused as new software. Needs,\\nthe necessity of re-engineering software has greatly increased. The system\\nsoftware has become obsolete no longer used in architecture, platform they're\\nrunning, stable and consistent they support the development and support needs\\nchange. Software re-engineering is vital to restore and reuse the things\\ninherent in the existing software, put the cost of software maintenance to the\\nlowest in the control and establish a basis for the development of software in\\nthe future.\",\n",
       "   'published': '2011-12-17',\n",
       "   'tags': 'cs.SE'}],\n",
       " [{'title': 'Disjunctive Databases for Representing Repairs',\n",
       "   'abstract': 'This paper addresses the problem of representing the set of repairs of a\\npossibly inconsistent database by means of a disjunctive database.\\nSpecifically, the class of denial constraints is considered. We show that,\\ngiven a database and a set of denial constraints, there exists a (unique)\\ndisjunctive database, called canonical, which represents the repairs of the\\ndatabase w.r.t. the constraints and is contained in any other disjunctive\\ndatabase with the same set of minimal models. We propose an algorithm for\\ncomputing the canonical disjunctive database. Finally, we study the size of the\\ncanonical disjunctive database in the presence of functional dependencies for\\nboth repairs and cardinality-based repairs.',\n",
       "   'published': '2008-11-13',\n",
       "   'tags': 'cs.DB'}],\n",
       " [{'title': 'Note on distance matrix hashing',\n",
       "   'abstract': 'Hashing algorithm of dynamical set of distances is described. Proposed\\nhashing function is residual. Data structure which implementation accelerates\\ncomputations is presented',\n",
       "   'published': '2019-01-24',\n",
       "   'tags': 'cs.DS'}],\n",
       " [{'title': 'Formation of General Position by Asynchronous Mobile Robots',\n",
       "   'abstract': 'The traditional distributed model of autonomous, homogeneous, mobile point\\nrobots usually assumes that the robots do not create any visual obstruction for\\nthe other robots, i.e., the robots are see through. In this paper, we consider\\na slightly more realistic model, by incorporating the notion of obstructed\\nvisibility (i.e., robots are not see through) for other robots. Under the new\\nmodel of visibility, a robot may not have the full view of its surroundings.\\nMany of the existing algorithms demand that each robot should have the complete\\nknowledge of the positions of other robots. Since, vision is the only mean of\\ntheir communication, it is required that the robots are in general position\\n(i.e., no three robots are collinear). We consider asynchronous robots. They\\nalso do not have common chirality (or any agreement on a global coordinate\\nsystem). In this paper, we present a distributed algorithm for obtaining a\\ngeneral position for the robots in finite time from any arbitrary\\nconfiguration. The algorithm also assures collision free motion for each robot.\\nThis algorithm may also be used as a preprocessing module for many other\\nsubsequent tasks performed by the robots.',\n",
       "   'published': '2014-08-09',\n",
       "   'tags': 'cs.DC'}],\n",
       " [{'title': 'Considerations for Cloud Security Operations',\n",
       "   'abstract': 'Information Security in Cloud Computing environments is explored. Cloud\\nComputing is presented, security needs are discussed, and mitigation approaches\\nare listed. Topics covered include Information Security, Cloud Computing,\\nPrivate Cloud, Public Cloud, SaaS, PaaS, IaaS, ISO 27001, OWASP, Secure SDLC.',\n",
       "   'published': '2016-01-23',\n",
       "   'tags': 'cs.CR'}],\n",
       " [{'title': 'The Influence of Social Networks on Human Society',\n",
       "   'abstract': 'This report gives a brief overview of the origin of social networks and their\\nmost popular manifestation in the modern era - the Online Social Networks\\n(OSNs) or social media. It further discusses the positive and negative\\nimplications of OSNs on human society. The coupling of Data Science and social\\nmedia (social media mining) is then put forward as a powerful tool to overcome\\nthe current challenges and pave the path for futuristic advancements',\n",
       "   'published': '2021-03-24',\n",
       "   'tags': 'cs.SI'}],\n",
       " [{'title': 'Stationary probability vectors of higher-order two-dimensional\\n  transition probability tensors',\n",
       "   'abstract': 'In this paper we investigate stationary probability vectors of higher-order\\ntwo-dimensional symmetric transition probability tensors. We show that there\\nare two special symmetric transition probability tensors of order $m$ dimension\\n2, which have and only have two stationary probability vectors; and any other\\nsymmetric transition probability tensor of order $m$ dimension 2 has a unique\\nstationary probability vector. As a byproduct, we obtain that any symmetric\\ntransition probability tensor of order $m$ dimension 2 has a unique positive\\nstationary probability vector; and that any symmetric irreducible transition\\nprobability tensor of order $m$ dimension 2 has a unique stationary probability\\nvector.',\n",
       "   'published': '2018-02-28',\n",
       "   'tags': 'math.SP'}],\n",
       " [{'title': 'Time optimal sampled-data controls for heat equations',\n",
       "   'abstract': 'In this paper, we first design a time optimal control problem for the heat\\nequation with sampled-data controls, and then use it to approximate a time\\noptimal control problem for the heat equation with distributed controls. Our\\ndesign is reasonable from perspective of sampled-data controls. And it might\\nprovide a right way for the numerical approach of a time optimal distributed\\ncontrol problem, via the corresponding semi-discretized (in time variable) time\\noptimal control problem.\\n  The study of such a time optimal sampled-data control problem is not easy,\\nbecause it may have infinitely many optimal controls. We find connections among\\nthis problem, a minimal norm sampled-data control problem and a minimization\\nproblem. And obtain some properties on these problems. Based on these, we not\\nonly build up error estimates for optimal time and optimal controls between the\\ntime optimal sampled-data control problem and the time optimal distributed\\ncontrol problem, in terms of the sampling period, but also prove that such\\nestimates are optimal in some sense.',\n",
       "   'published': '2017-01-22',\n",
       "   'tags': 'math.OC'}],\n",
       " [{'title': 'Improving One-Shot Learning through Fusing Side Information',\n",
       "   'abstract': \"Deep Neural Networks (DNNs) often struggle with one-shot learning where we\\nhave only one or a few labeled training examples per category. In this paper,\\nwe argue that by using side information, we may compensate the missing\\ninformation across classes. We introduce two statistical approaches for fusing\\nside information into data representation learning to improve one-shot\\nlearning. First, we propose to enforce the statistical dependency between data\\nrepresentations and multiple types of side information. Second, we introduce an\\nattention mechanism to efficiently treat examples belonging to the\\n'lots-of-examples' classes as quasi-samples (additional training samples) for\\n'one-example' classes. We empirically show that our learning architecture\\nimproves over traditional softmax regression networks as well as\\nstate-of-the-art attentional regression networks on one-shot recognition tasks.\",\n",
       "   'published': '2017-10-23',\n",
       "   'tags': 'cs.LG'}],\n",
       " [{'title': 'When does a physical system compute?',\n",
       "   'abstract': \"Computing is a high-level process of a physical system. Recent interest in\\nnon-standard computing systems, including quantum and biological computers, has\\nbrought this physical basis of computing to the forefront. There has been,\\nhowever, no consensus on how to tell if a given physical system is acting as a\\ncomputer or not; leading to confusion over novel computational devices, and\\neven claims that every physical event is a computation. In this paper we\\nintroduce a formal framework that can be used to determine whether or not a\\nphysical system is performing a computation. We demonstrate how the abstract\\ncomputational level interacts with the physical device level, drawing the\\ncomparison with the use of mathematical models to represent physical objects in\\nexperimental science. This powerful formulation allows a precise description of\\nthe similarities between experiments, computation, simulation, and technology,\\nleading to our central conclusion: physical computing is the use of a physical\\nsystem to predict the outcome of an abstract evolution. We give conditions that\\nmust be satisfied in order for computation to be occurring, and illustrate\\nthese with a range of non-standard computing scenarios. The framework also\\ncovers broader computing contexts, where there is no obvious human computer\\nuser. We define the critical notion of a 'computational entity', and show the\\nrole this plays in defining when computing is taking place in physical systems.\",\n",
       "   'published': '2013-09-30',\n",
       "   'tags': 'cs.ET'}],\n",
       " [{'title': 'Minimum Sliced Distance Estimation in a Class of Nonregular Econometric\\n  Models',\n",
       "   'abstract': 'This paper proposes minimum sliced distance estimation in structural\\neconometric models with possibly parameter-dependent supports. In contrast to\\nlikelihood-based estimation, we show that under mild regularity conditions, the\\nminimum sliced distance estimator is asymptotically normally distributed\\nleading to simple inference regardless of the presence/absence of parameter\\ndependent supports. We illustrate the performance of our estimator on an\\nauction model.',\n",
       "   'published': '2024-12-07',\n",
       "   'tags': 'econ.EM'}],\n",
       " [{'title': 'Fully Convolutional Generative Machine Learning Method for Accelerating\\n  Non-Equilibrium Greens Function Simulations',\n",
       "   'abstract': 'This work describes a novel simulation approach that combines machine\\nlearning and device modelling simulations. The device simulations are based on\\nthe quantum mechanical non-equilibrium Greens function (NEGF) approach and the\\nmachine learning method is an extension to a convolutional generative network.\\nWe have named our new simulation approach ML-NEGF and we have implemented it in\\nour in-house simulator called NESS (nano-electronics simulations software). The\\nreported results demonstrate the improved convergence speed of the ML-NEGF\\nmethod in comparison to the standard NEGF approach. The trained ML model\\neffectively learns the underlying physics of nano-sheet transistor behaviour,\\nresulting in faster convergence of the coupled Poisson-NEGF simulations.\\nQuantitatively, our ML- NEGF approach achieves an average convergence\\nacceleration of 60%, substantially reducing the computational time while\\nmaintaining the same accuracy.',\n",
       "   'published': '2023-09-17',\n",
       "   'tags': 'cs.CE'}]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d63537a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence\n",
      "===============================================\n",
      "Computation and Language (NLP)\n",
      "===============================================\n",
      "Computer Vision and Pattern Recognition\n",
      "===============================================\n",
      "Machine Learning\n",
      "===============================================\n",
      "Information Retrieval\n",
      "===============================================\n",
      "Software Engineering\n",
      "===============================================\n",
      "Databases\n",
      "===============================================\n",
      "Data Structures and Algorithms\n",
      "===============================================\n",
      "Robotics\n",
      "===============================================\n",
      "Cryptography and Security\n",
      "===============================================\n",
      "Social and Information Networks\n",
      "===============================================\n",
      "Probability\n",
      "===============================================\n",
      "Optimization and Control\n",
      "===============================================\n",
      "Machine Learning (Statistics side)\n",
      "===============================================\n",
      "Computational Physics\n",
      "===============================================\n",
      "Econometrics\n",
      "===============================================\n",
      "Quantitative Finance – ML\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime(2019, 1, 1)\n",
    "end = datetime(2024, 1, 1)\n",
    "\n",
    "data = []\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    papers = fetch_arxiv_data(topic, 200)\n",
    "    data.append(papers)\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a53c933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_papers = [paper for batch in data for paper in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89720d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs.AI', 'q-fin.TR', 'q-fin.GN', 'cs.CY', 'cs.IR', 'cs.HC',\n",
       "       'astro-ph.IM', 'math.GM', 'cs.LG', 'cs.RO', 'cs.CR', 'cs.NE',\n",
       "       'physics.pop-ph', 'q-bio.NC', 'cs.CL', 'q-bio.QM', 'cs.CV',\n",
       "       'cs.IT', 'cs.ET', 'physics.data-an', 'cs.SE', 'cs.DL', 'quant-ph',\n",
       "       'cs.NI', 'q-fin.RM', 'cs.DC', 'cmp-lg', 'q-bio.BM', 'eess.IV',\n",
       "       'nlin.AO', 'cs.CG', 'cs.CC', 'eess.SP', 'math.AG', 'cs.GR',\n",
       "       'physics.med-ph', 'physics.ao-ph', 'stat.ML', 'physics.comp-ph',\n",
       "       'stat.CO', 'cond-mat.mtrl-sci', 'cs.CE', 'cs.FL', 'math.NA',\n",
       "       'q-fin.ST', 'stat.ME', 'q-bio.MN', 'econ.EM', 'q-bio.PE',\n",
       "       'physics.chem-ph', 'stat.AP', 'cs.GT', 'cs.MM', 'math.FA', 'cs.MS',\n",
       "       'cs.MA', 'cs.DB', 'physics.acc-ph', 'math.GR', 'cs.DS', 'astro-ph',\n",
       "       'cs.SD', 'cs.LO', 'math.CO', 'q-bio.GN', 'astro-ph.SR',\n",
       "       'astro-ph.HE', 'math.OC', 'eess.SY', 'cs.PL', 'cs.SI',\n",
       "       'physics.soc-ph', 'econ.TH', 'math.PR', 'math.SP', 'math-ph',\n",
       "       'stat.OT', 'math.LO', 'math.ST', 'math.OA', 'physics.gen-ph',\n",
       "       'math.QA', 'math.RA', 'cond-mat.stat-mech', 'math.HO', 'cs.SY',\n",
       "       'gr-qc', 'astro-ph.EP', 'hep-th', 'physics.flu-dyn', 'math.DS',\n",
       "       'math.AT', 'cond-mat.mes-hall', 'cs.SC', 'math.AP', 'math.DG',\n",
       "       'hep-lat', 'q-fin.MF', 'eess.AS', 'hep-ex', 'physics.geo-ph',\n",
       "       'cond-mat.dis-nn', 'astro-ph.CO', 'econ.GN', 'q-fin.PR',\n",
       "       'physics.ed-ph', 'cs.GL', 'hep-ph', 'physics.bio-ph',\n",
       "       'physics.plasm-ph', 'physics.optics', 'cs.OH', 'physics.hist-ph',\n",
       "       'nlin.SI', 'nucl-th', 'q-fin.CP', 'q-fin.PM', 'cond-mat.soft',\n",
       "       'q-bio.OT', 'cond-mat', 'q-bio.TO'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(flattened_papers)['tags'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "756e025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence', 'Computation and Language (NLP)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b4543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
